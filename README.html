<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>README</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="./github-pandoc.css" />
</head>
<body>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#td1">TD1</a></li>
<li><a href="#i.-partie-1">I. Partie 1</a>
<ul>
<li><a href="#produit-matrice-matrice">Produit matrice-matrice</a>
<ul>
<li><a href="#effet-de-la-taille-de-la-matrice">Effet de la taille de la matrice</a></li>
<li><a href="#permutation-des-boucles">Permutation des boucles</a></li>
<li><a href="#omp-sur-la-meilleure-boucle">OMP sur la meilleure boucle</a></li>
<li><a href="#produit-par-blocs">Produit par blocs</a></li>
<li><a href="#bloc-omp">Bloc + OMP</a></li>
<li><a href="#comparaison-avec-blas-eigen-et-numpy">Comparaison avec BLAS, Eigen et numpy</a></li>
<li><a href="#tips">Tips</a></li>
</ul></li>
</ul></li>
<li><a href="#ii.-partie-2">II. Partie 2</a></li>
<li><a href="#r√©sultats-des-temps-dex√©cution-mpi">2.1 R√©sultats des temps d‚Äôex√©cution MPI</a>
<ul>
<li><a href="#tableau-des-temps-dex√©cution">Tableau des temps d‚Äôex√©cution</a></li>
<li><a href="#calcul-du-speedup">Calcul du Speedup</a></li>
<li><a href="#analyse-des-r√©sultats">Analyse des r√©sultats</a></li>
</ul></li>
<li><a href="#r√©sultats-des-temps-dex√©cution-openmp">2.2 R√©sultats des temps d‚Äôex√©cution OpenMP</a>
<ul>
<li><a href="#tableau-des-temps-dex√©cution-openmp">Tableau des temps d‚Äôex√©cution OpenMP</a></li>
<li><a href="#calcul-du-speedup-openmp">Calcul du Speedup OpenMP</a></li>
<li><a href="#analyse-des-r√©sultats-openmp">Analyse des r√©sultats OpenMP</a></li>
</ul></li>
<li><a href="#r√©sultats-des-temps-dex√©cution-mpi-et-openmp">R√©sultats des temps d‚Äôex√©cution MPI et OpenMP</a>
<ul>
<li><a href="#tableau-des-temps-dex√©cution-mpi-python">Tableau des temps d‚Äôex√©cution MPI (Python)</a></li>
<li><a href="#calcul-du-speedup-mpi-python">Calcul du Speedup MPI (Python)</a></li>
<li><a href="#analyse-des-r√©sultats-mpi-python">Analyse des r√©sultats MPI (Python)</a></li>
</ul></li>
</ul>
</nav>
<h1 id="td1">TD1</h1>
<h4 id="qizheng-wang">Qizheng WANG</h4>
<h1 id="i.-partie-1">I. Partie 1</h1>
<p><code>pandoc -s --toc README.md --css=./github-pandoc.css -o README.html</code></p>
<h2 id="produit-matrice-matrice">Produit matrice-matrice</h2>
<h3 id="effet-de-la-taille-de-la-matrice">Effet de la taille de la matrice</h3>
<table>
<thead>
<tr class="header">
<th>n</th>
<th>MFlops</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1024 (origine)</td>
<td>61.6447</td>
</tr>
<tr class="even">
<td>1023</td>
<td>96.6385</td>
</tr>
<tr class="odd">
<td>1025</td>
<td>96.7703</td>
</tr>
</tbody>
</table>
<p><em>Expliquer les r√©sultatsÔºö</em></p>
<p><em>Les r√©sultats montrent une variation significative des performances en fonction de la taille de la matrice. Pour ùëõ=1024 n=1024, la performance est plus faible (61.64 MFlops) par rapport aux tailles non align√©es ùëõ=1023 n=1023 et ùëõ=1025 n=1025 (~96.7 MFlops). Cette diff√©rence est due √† l‚Äôalignement m√©moire : 1024 est une puissance de 2, ce qui peut entra√Æner des conflits de cache (cache associatif), tandis que 1023 et 1025 r√©partissent mieux les acc√®s m√©moire, r√©duisant les cache misses et am√©liorant ainsi la performance.</em></p>
<h3 id="permutation-des-boucles">Permutation des boucles</h3>
<p><em>Expliquer comment est compil√© le code (ligne de make ou de gcc) : on aura besoin de savoir l‚Äôoptim, les param√®tres, etc. Par exemple :</em></p>
<p><code>make TestProduct.exe &amp;&amp; ./TestProduct.exe 1024</code></p>
<table>
<thead>
<tr class="header">
<th>ordre</th>
<th>time</th>
<th>MFlops</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>i,j,k (origine)</td>
<td>16.0961</td>
<td>133.417</td>
</tr>
<tr class="even">
<td>j,i,k</td>
<td>23.5417</td>
<td>91.2202</td>
</tr>
<tr class="odd">
<td>i,k,j</td>
<td>39.2870</td>
<td>54.6614</td>
</tr>
<tr class="even">
<td>k,i,j</td>
<td>28.3425</td>
<td>75.7691</td>
</tr>
<tr class="odd">
<td>j,k,i</td>
<td>12.0201</td>
<td>178.658</td>
</tr>
<tr class="even">
<td>k,j,i</td>
<td>13.5173</td>
<td>158.869</td>
</tr>
</tbody>
</table>
<p><em>Discuter les r√©sultats.</em></p>
<p>Les r√©sultats montrent une forte d√©pendance de la performance √† l‚Äôordre des boucles. L‚Äôordre j,k,i est le plus rapide (12.02s, 178.66 MFlops), suivi de k,j,i (13.52s, 158.87 MFlops), indiquant une meilleure exploitation du cache et de la localit√© m√©moire. Ces r√©sultats sugg√®rent que prioriser l‚Äôit√©ration sur les colonnes (j) ou les lignes (k) avant les multiplications internes am√©liore les performances.</p>
<h3 id="omp-sur-la-meilleure-boucle">OMP sur la meilleure boucle</h3>
<p><code>make TestProduct.exe &amp;&amp; OMP_NUM_THREADS=8 ./TestProduct.exe 1024</code></p>
<table>
<thead>
<tr class="header">
<th>OMP_NUM</th>
<th>MFlops</th>
<th>MFlops(n=2048)</th>
<th>MFlops(n=512)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>17.8758</td>
<td>17.8758</td>
<td>36.5950</td>
</tr>
<tr class="even">
<td>2</td>
<td>34.0799</td>
<td>19.6172</td>
<td>49.5074</td>
</tr>
<tr class="odd">
<td>3</td>
<td>51.9702</td>
<td>19.6053</td>
<td>53.0270</td>
</tr>
<tr class="even">
<td>4</td>
<td>51.9944</td>
<td>19.3541</td>
<td>87.4854</td>
</tr>
<tr class="odd">
<td>5</td>
<td>55.4674</td>
<td>19.2349</td>
<td>95.6910</td>
</tr>
<tr class="even">
<td>6</td>
<td>54.6610</td>
<td>22.0020</td>
<td>88.8524</td>
</tr>
<tr class="odd">
<td>7</td>
<td>58.7588</td>
<td>51.5638</td>
<td>109.757</td>
</tr>
<tr class="even">
<td>8</td>
<td>63.2577</td>
<td>54.3109</td>
<td>81.0722</td>
</tr>
</tbody>
</table>
<p><em>Tracer les courbes de speedup (pour chaque valeur de n), discuter les r√©sultats.</em> <img src="./output.png" alt="Description" /></p>
<p>Les courbes de speedup montrent une acc√©l√©ration variable en fonction de la taille de la matrice et du nombre de threads. Pour ( n=1024 ) et ( n=512 ), le speedup est presque lin√©aire jusqu‚Äô√† 8 threads, indiquant une bonne scalabilit√©. Cependant, pour ( n=2048 ), l‚Äôacc√©l√©ration reste faible jusqu‚Äô√† 6 threads, puis augmente fortement √† 7 et 8 threads. Cela peut √™tre d√ª √† la saturation de la bande passante m√©moire et √† une mauvaise exploitation du cache pour de grandes matrices.</p>
<h3 id="produit-par-blocs">Produit par blocs</h3>
<p><code>make TestProduct.exe &amp;&amp; ./TestProduct.exe 1024</code></p>
<table>
<thead>
<tr class="header">
<th>szBlock</th>
<th>MFlops</th>
<th>MFlops(n=2048)</th>
<th>MFlops(n=512)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>origine (=max)</td>
<td>133.417</td>
<td>138.241</td>
<td>159.076</td>
</tr>
<tr class="even">
<td>32</td>
<td>151.514</td>
<td>146.692</td>
<td>171.390</td>
</tr>
<tr class="odd">
<td>64</td>
<td>156.570</td>
<td>151.630</td>
<td>163.212</td>
</tr>
<tr class="even">
<td>128</td>
<td>159.440</td>
<td>157.445</td>
<td>167.792</td>
</tr>
<tr class="odd">
<td>256</td>
<td>150.700</td>
<td>148.322</td>
<td>153.776</td>
</tr>
<tr class="even">
<td>512</td>
<td>110.821</td>
<td>109.987</td>
<td>139.625</td>
</tr>
<tr class="odd">
<td>1024</td>
<td>51.7021</td>
<td>52.4546</td>
<td>80.7186</td>
</tr>
</tbody>
</table>
<p><em>Discuter les r√©sultats.</em> L‚Äôoptimisation par blocs am√©liore la performance du produit matrice-matrice en exploitant mieux la hi√©rarchie de la m√©moire cache. On observe que la performance (en MFlops) augmente avec la taille du bloc jusqu‚Äô√† un certain seuil, avec un maximum autour de 128. Au-del√† de cette valeur, les performances diminuent, notamment pour <code>szBlock = 512</code> et <code>1024</code>, car les blocs deviennent trop grands pour tenir dans le cache L1 ou L2.</p>
<h3 id="bloc-omp">Bloc + OMP</h3>
<table>
<thead>
<tr class="header">
<th>szBlock</th>
<th>OMP_NUM</th>
<th>MFlops</th>
<th>MFlops(n=2048)</th>
<th>MFlops(n=512)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1024</td>
<td>1</td>
<td>58.7836</td>
<td>34.3739</td>
<td>97.9819</td>
</tr>
<tr class="even">
<td>1024</td>
<td>8</td>
<td>61.8933</td>
<td>43.2985</td>
<td>133.653</td>
</tr>
<tr class="odd">
<td>512</td>
<td>1</td>
<td>130.785</td>
<td>120.942</td>
<td>137.855</td>
</tr>
<tr class="even">
<td>512</td>
<td>8</td>
<td>133.325</td>
<td>122.377</td>
<td>123.671</td>
</tr>
</tbody>
</table>
<p><em>Discuter les r√©sultats.</em></p>
<p>L‚Äôoptimisation par blocs am√©liore les performances tant que la taille des blocs reste adapt√©e √† la capacit√© du cache. Un szBlock trop grand r√©duit les performances √† cause des cache misses et du mauvais √©quilibrage du travail entre threads. Dans ce cas, szBlock = 512 semble √™tre le meilleur compromis pour tirer profit √† la fois du cache et du parall√©lisme.</p>
<h3 id="comparaison-avec-blas-eigen-et-numpy">Comparaison avec BLAS, Eigen et numpy</h3>
<p><em>Comparer les performances avec un calcul similaire utilisant les biblioth√®ques d‚Äôalg√®bre lin√©aire BLAS, Eigen et/ou numpy.</em></p>
<div class="line-block">Biblioth√®ques | MFlops | MFlops(n=2048) |<br />
¬†¬†¬†¬†¬†BLAS | 39426.9 | 35753.1 |</div>
<p>Les performances du produit matrice-matrice avec BLAS sont plusieurs ordres de grandeur sup√©rieures √† celles de notre impl√©mentation optimis√©e. Parce que BLAS a exploite des optimisations bas niveau.</p>
<h3 id="tips">Tips</h3>
<pre><code>    env
    OMP_NUM_THREADS=4 ./produitMatriceMatrice.exe</code></pre>
<pre><code>    $ for i in $(seq 1 4); do elap=$(OMP_NUM_THREADS=$i ./TestProductOmp.exe|grep &quot;Temps CPU&quot;|cut -d &quot; &quot; -f 7); echo -e &quot;$i\t$elap&quot;; done &gt; timers.out</code></pre>
<h1 id="ii.-partie-2">II. Partie 2</h1>
<h1 id="r√©sultats-des-temps-dex√©cution-mpi">2.1 R√©sultats des temps d‚Äôex√©cution MPI</h1>
<h2 id="tableau-des-temps-dex√©cution">Tableau des temps d‚Äôex√©cution</h2>
<table>
<thead>
<tr class="header">
<th>Nombre de processus (p)</th>
<th>Temps d‚Äôex√©cution (s)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.003123</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.004135</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.042656</td>
</tr>
<tr class="even">
<td>8</td>
<td>0.223999</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="calcul-du-speedup">Calcul du Speedup</h2>
<p>Le Speedup est d√©fini par la formule :</p>
<p>[ S(p) =  ]</p>
<table>
<thead>
<tr class="header">
<th>Nombre de processus (p)</th>
<th>Temps d‚Äôex√©cution (s)</th>
<th>Speedup ( S(p) )</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.003123</td>
<td>1.00</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.004135</td>
<td>1.51</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.042656</td>
<td>0.29</td>
</tr>
<tr class="even">
<td>8</td>
<td>0.223999</td>
<td>0.11</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="analyse-des-r√©sultats">Analyse des r√©sultats</h2>
<ul>
<li>On observe que le temps d‚Äôex√©cution n‚Äôest pas lin√©airement r√©duit avec l‚Äôaugmentation du nombre de processus.</li>
<li>Le Speedup est bien inf√©rieur √† l‚Äôid√©al (qui serait proche de p). Cela indique probablement que la communication MPI domine le temps de calcul, rendant l‚Äôex√©cution inefficace au-del√† de 4 processus.</li>
</ul>
<h1 id="r√©sultats-des-temps-dex√©cution-openmp">2.2 R√©sultats des temps d‚Äôex√©cution OpenMP</h1>
<h2 id="tableau-des-temps-dex√©cution-openmp">Tableau des temps d‚Äôex√©cution OpenMP</h2>
<table>
<thead>
<tr class="header">
<th>Nombre de threads (p)</th>
<th>Temps d‚Äôex√©cution (s)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.000542</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.000844</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.000848</td>
</tr>
<tr class="even">
<td>8</td>
<td>0.002269</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="calcul-du-speedup-openmp">Calcul du Speedup OpenMP</h2>
<p>Le Speedup est d√©fini par la formule :</p>
<p>[ S(p) =  ]</p>
<table>
<thead>
<tr class="header">
<th>Nombre de threads (p)</th>
<th>Temps d‚Äôex√©cution (s)</th>
<th>Speedup ( S(p) )</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.000542</td>
<td>1.00</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.000844</td>
<td>1.28</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.000848</td>
<td>2.55</td>
</tr>
<tr class="even">
<td>8</td>
<td>0.002269</td>
<td>1.92</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="analyse-des-r√©sultats-openmp">Analyse des r√©sultats OpenMP</h2>
<p>Le Speedup attendu en OpenMP est g√©n√©ralement lin√©aire avec le nombre de threads, mais ici, on observe une acc√©l√©ration tr√®s faible, ce qui indique probablement une surcharge due √† la gestion des threads ou un manque d‚Äôoptimisation des acc√®s m√©moire.</p>
<h1 id="r√©sultats-des-temps-dex√©cution-mpi-et-openmp">R√©sultats des temps d‚Äôex√©cution MPI et OpenMP</h1>
<h2 id="tableau-des-temps-dex√©cution-mpi-python">Tableau des temps d‚Äôex√©cution MPI (Python)</h2>
<table>
<thead>
<tr class="header">
<th>Nombre de processus (p)</th>
<th>Temps d‚Äôex√©cution (s)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.006500</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.023315</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.129870</td>
</tr>
<tr class="even">
<td>8</td>
<td>0.463661</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="calcul-du-speedup-mpi-python">Calcul du Speedup MPI (Python)</h2>
<p>[ S(p) =  ]</p>
<table>
<thead>
<tr class="header">
<th>Nombre de processus (p)</th>
<th>Temps d‚Äôex√©cution (s)</th>
<th>Speedup ( S(p) )</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.016500</td>
<td>1.00</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.034021</td>
<td>0.97</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.068253</td>
<td>0.96</td>
</tr>
<tr class="even">
<td>8</td>
<td>0.148798</td>
<td>0.88</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="analyse-des-r√©sultats-mpi-python">Analyse des r√©sultats MPI (Python)</h2>
<p>Contrairement √† ce qu‚Äôon pourrait attendre, l‚Äôaugmentation du nombre de processus entra√Æne une d√©gradation des performances, ce qui indique que la communication MPI devient un goulot d‚Äô√©tranglement.</p>
</body>
</html>
